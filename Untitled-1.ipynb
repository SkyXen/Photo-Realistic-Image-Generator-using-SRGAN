{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# from keras_preprocessing.image import img_to_array, load_img, save_img\n",
    "# from tensorflow.keras.preprocessing.image import smart_resize\n",
    "\n",
    "#use save_img in place of imsave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PREPROCESSING\n",
    "\n",
    "train_dir = \"data\"\n",
    "\n",
    "for img in os.listdir(train_dir + \"/original\"):\n",
    "    img_arr = cv2.imread(train_dir + \"/original/\" + img)\n",
    "    img_arr = cv2.resize(img_arr,(128,128))\n",
    "    lr_img_arr = cv2.resize(img_arr,(32,32))\n",
    "    cv2.imwrite(train_dir + \"/hr/\" + img, img_arr)\n",
    "    cv2.imwrite(train_dir + \"/lr/\" + img, lr_img_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters for generator network\n",
    "residual_blocks = 16\n",
    "momentum = 0.8\n",
    "input_shape = (64, 64, 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The input layer takes an input image of a shape of (64, 64, 3) and passes it to the next layer in the network.\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "#Pre-residual 2D convolution block\n",
    "gen1 = Conv2D(filters=64, kernel_size=9, strides=1, padding='same', activation='relu')(input_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x):\n",
    "    \"\"\"\n",
    "    Residual block\n",
    "    \"\"\"\n",
    "    filters = [64, 64]\n",
    "    kernel_size = 3\n",
    "    strides = 1\n",
    "    padding = \"same\"\n",
    "    momentum = 0.8\n",
    "    activation = \"relu\"\n",
    "\n",
    "    res = Conv2D(filters=filters[0], kernel_size=kernel_size, \n",
    "                 strides=strides, padding=padding)(x)\n",
    "    res = Activation(activation=activation)(res)\n",
    "    res = BatchNormalization(momentum=momentum)(res)\n",
    "\n",
    "    res = Conv2D(filters=filters[1], kernel_size=kernel_size, \n",
    "                 strides=strides, padding=padding)(res)\n",
    "    res = BatchNormalization(momentum=momentum)(res)\n",
    "\n",
    "    # Add res and x\n",
    "    res = Add()([res, x])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator Network\n",
    "def build_generator():\n",
    "    \"\"\"\n",
    "    Create a generator network using the hyperparameter values defined below\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    residual_blocks = 16\n",
    "    momentum = 0.8\n",
    "    input_shape = (64, 64, 3)\n",
    "\n",
    "    # Input Layer of the generator network\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # Add the pre-residual block\n",
    "    gen1 = Conv2D(filters=64, kernel_size=9, strides=1, padding='same',  \n",
    "                  activation='relu')(input_layer)\n",
    "\n",
    "    # Add 16 residual blocks\n",
    "    res = residual_block(gen1)\n",
    "    for i in range(residual_blocks - 1):\n",
    "        res = residual_block(res)\n",
    "\n",
    "    # Add the post-residual block\n",
    "    gen2 = Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(res)\n",
    "    gen2 = BatchNormalization(momentum=momentum)(gen2)\n",
    "\n",
    "    # Take the sum of the output from the pre-residual block(gen1) and the post-residual block(gen2)\n",
    "    gen3 = Add()([gen2, gen1])\n",
    "\n",
    "    # Add an upsampling block\n",
    "    gen4 = UpSampling2D(size=2)(gen3)\n",
    "    gen4 = Conv2D(filters=256, kernel_size=3, strides=1, padding='same')(gen4)\n",
    "    gen4 = Activation('relu')(gen4)\n",
    "\n",
    "    # Add another upsampling block\n",
    "    gen5 = UpSampling2D(size=2)(gen4)\n",
    "    gen5 = Conv2D(filters=256, kernel_size=3, strides=1, \n",
    "                  padding='same')(gen5)\n",
    "    gen5 = Activation('relu')(gen5)\n",
    "\n",
    "    # Output convolution layer\n",
    "    gen6 = Conv2D(filters=3, kernel_size=9, strides=1, padding='same')(gen5)\n",
    "    output = Activation('tanh')(gen6)\n",
    "\n",
    "    # Keras model\n",
    "    model = Model(inputs=[input_layer], outputs=[output], \n",
    "                  name='generator')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    \"\"\"\n",
    "    Create a discriminator network using the hyperparameter values defined below\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    leakyrelu_alpha = 0.2\n",
    "    momentum = 0.8\n",
    "    input_shape = (256, 256, 3)\n",
    "\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # Add the first convolution block\n",
    "    dis1 = Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(input_layer)\n",
    "    dis1 = LeakyReLU(alpha=leakyrelu_alpha)(dis1)\n",
    "\n",
    "    # Add the 2nd convolution block\n",
    "    dis2 = Conv2D(filters=64, kernel_size=3, strides=2, padding='same')(dis1)\n",
    "    dis2 = LeakyReLU(alpha=leakyrelu_alpha)(dis2)\n",
    "    dis2 = BatchNormalization(momentum=momentum)(dis2)\n",
    "\n",
    "    # Add the third convolution block\n",
    "    dis3 = Conv2D(filters=128, kernel_size=3, strides=1, padding='same')(dis2)\n",
    "    dis3 = LeakyReLU(alpha=leakyrelu_alpha)(dis3)\n",
    "    dis3 = BatchNormalization(momentum=momentum)(dis3)\n",
    "\n",
    "    # Add the fourth convolution block\n",
    "    dis4 = Conv2D(filters=128, kernel_size=3, strides=2, padding='same')(dis3)\n",
    "    dis4 = LeakyReLU(alpha=leakyrelu_alpha)(dis4)\n",
    "    dis4 = BatchNormalization(momentum=0.8)(dis4)\n",
    "\n",
    "    # Add the fifth convolution block\n",
    "    dis5 = Conv2D(256, kernel_size=3, strides=1, padding='same')(dis4)\n",
    "    dis5 = LeakyReLU(alpha=leakyrelu_alpha)(dis5)\n",
    "    dis5 = BatchNormalization(momentum=momentum)(dis5)\n",
    "\n",
    "    # Add the sixth convolution block\n",
    "    dis6 = Conv2D(filters=256, kernel_size=3, strides=2, padding='same')(dis5)\n",
    "    dis6 = LeakyReLU(alpha=leakyrelu_alpha)(dis6)\n",
    "    dis6 = BatchNormalization(momentum=momentum)(dis6)\n",
    "\n",
    "    # Add the seventh convolution block\n",
    "    dis7 = Conv2D(filters=512, kernel_size=3, strides=1, padding='same')(dis6)\n",
    "    dis7 = LeakyReLU(alpha=leakyrelu_alpha)(dis7)\n",
    "    dis7 = BatchNormalization(momentum=momentum)(dis7)\n",
    "\n",
    "    # Add the eight convolution block\n",
    "    dis8 = Conv2D(filters=512, kernel_size=3, strides=2, padding='same')(dis7)\n",
    "    dis8 = LeakyReLU(alpha=leakyrelu_alpha)(dis8)\n",
    "    dis8 = BatchNormalization(momentum=momentum)(dis8)\n",
    "\n",
    "    # Add a dense layer\n",
    "    dis9 = Dense(units=1024)(dis8)\n",
    "    dis9 = LeakyReLU(alpha=0.2)(dis9)\n",
    "\n",
    "    # Last dense layer - for classification\n",
    "    output = Dense(units=1, activation='sigmoid')(dis9)\n",
    "\n",
    "    model = Model(inputs=[input_layer], outputs=[output], name='discriminator')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_adversarial_model(generator, discriminator, vgg):\n",
    "\n",
    "    input_low_resolution = Input(shape=(64, 64, 3))\n",
    "\n",
    "    fake_hr_images = generator(input_low_resolution)\n",
    "    fake_features = vgg(fake_hr_images)\n",
    "\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    output = discriminator(fake_hr_images)\n",
    "\n",
    "    model = Model(inputs=[input_low_resolution],\n",
    "                  outputs=[output, fake_features])\n",
    "\n",
    "    for layer in model.layers:\n",
    "        print(layer.name, layer.trainable)\n",
    "\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(data_dir, batch_size, high_resolution_shape, low_resolution_shape):\n",
    "    # Make a list of all images inside the data directory\n",
    "    all_images = glob.glob(data_dir)\n",
    "\n",
    "    # Choose a random batch of images\n",
    "    images_batch = np.random.choice(all_images, size=batch_size)\n",
    "\n",
    "    low_resolution_images = []\n",
    "    high_resolution_images = []\n",
    "\n",
    "    for img in images_batch:\n",
    "        # Get an ndarray of the current image\n",
    "        img1 = load_img(img, mode='RGB')\n",
    "        img1 = img1.astype(np.float32)\n",
    "\n",
    "        # Resize the image\n",
    "        img1_high_resolution = smart_resize(img1, high_resolution_shape)\n",
    "        img1_low_resolution = smart_resize(img1, low_resolution_shape)\n",
    "\n",
    "        # Do a random flip\n",
    "        if np.random.random() < 0.5:\n",
    "            img1_high_resolution = np.fliplr(img1_high_resolution)\n",
    "            img1_low_resolution = np.fliplr(img1_low_resolution)\n",
    "\n",
    "        high_resolution_images.append(img1_high_resolution)\n",
    "        low_resolution_images.append(img1_low_resolution)\n",
    "\n",
    "    return np.array(high_resolution_images), np.array(low_resolution_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vgg(high_resolution_shape):\n",
    "    vgg = VGG19(weights = 'imagenet', include_top=False, input_shape=high_resolution_shape)\n",
    "\n",
    "    return Model(inputs = vgg.inputs, outputs = vgg.layers[10].output)\n",
    "\n",
    "def create_combination(generator,discriminator,vgg,input_low_resolution,input_high_resolution):\n",
    "    generated_high_resolution_images = generator(input_low_resolution)\n",
    "\n",
    "    features = vgg(generated_high_resolution_images)\n",
    "\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    probs = discriminator(generated_high_resolution_images)\n",
    "\n",
    "    adversarial_model = Model([input_low_resolution, input_high_resolution], [probs, features])\n",
    "    \n",
    "    return adversarial_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Laoding images\n",
    "n = 5000\n",
    "lr_list = os.listdir(\"data/lr\")[:n]\n",
    "\n",
    "lr_images = []\n",
    "for img in lr_list:\n",
    "    \n",
    "\n",
    "for img in lr_list:\n",
    "    img_lr = cv2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "data_dir = \"img_align_celeba/*.*\"\n",
    "epochs = 20000\n",
    "batch_size = 1\n",
    "\n",
    "# Shape of low-resolution and high-resolution images\n",
    "low_resolution_shape = (64, 64, 3)\n",
    "high_resolution_shape = (256, 256, 3)\n",
    "\n",
    "# Common optimizer for all networks\n",
    "common_optimizer = Adam(0.0002, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 14:09:22.324847: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 411041792 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_25'), name='input_25', description=\"created by layer 'input_25'\"), but it was called on an input with incompatible shape (None, 256, 256, 3).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer fc1 is incompatible with the layer: expected axis -1 of input shape to have value 25088 but received input with shape (None, 32768)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m input_low_resolution \u001b[39m=\u001b[39m Input(shape\u001b[39m=\u001b[39mlow_resolution_shape)\n\u001b[1;32m     15\u001b[0m generated_high_resolution_images \u001b[39m=\u001b[39m generator(input_low_resolution)\n\u001b[0;32m---> 17\u001b[0m features \u001b[39m=\u001b[39m vgg(generated_high_resolution_images)\n\u001b[1;32m     19\u001b[0m discriminator\u001b[39m.\u001b[39mtrainable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     21\u001b[0m probs \u001b[39m=\u001b[39m discriminator(generated_high_resolution_images)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:951\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[39m# Functional Model construction mode is invoked when `Layer`s are called on\u001b[39;00m\n\u001b[1;32m    946\u001b[0m \u001b[39m# symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[1;32m    947\u001b[0m \u001b[39m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[1;32m    949\u001b[0m \u001b[39m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[1;32m    950\u001b[0m \u001b[39mif\u001b[39;00m _in_functional_construction_mode(\u001b[39mself\u001b[39m, inputs, args, kwargs, input_list):\n\u001b[0;32m--> 951\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_functional_construction_call(inputs, args, kwargs,\n\u001b[1;32m    952\u001b[0m                                             input_list)\n\u001b[1;32m    954\u001b[0m \u001b[39m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[1;32m    955\u001b[0m call_context \u001b[39m=\u001b[39m base_layer_utils\u001b[39m.\u001b[39mcall_context()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:1090\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[39mif\u001b[39;00m keras_tensor\u001b[39m.\u001b[39mkeras_tensors_enabled():\n\u001b[1;32m   1087\u001b[0m   \u001b[39mwith\u001b[39;00m call_context\u001b[39m.\u001b[39menter(\n\u001b[1;32m   1088\u001b[0m       layer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, inputs\u001b[39m=\u001b[39minputs, build_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39mtraining_value):\n\u001b[1;32m   1089\u001b[0m     \u001b[39m# Check input assumptions set after layer building, e.g. input shape.\u001b[39;00m\n\u001b[0;32m-> 1090\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_keras_tensor_symbolic_call(\n\u001b[1;32m   1091\u001b[0m         inputs, input_masks, args, kwargs)\n\u001b[1;32m   1093\u001b[0m     \u001b[39mif\u001b[39;00m outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1094\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mA layer\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39ms `call` method should return a \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1095\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mTensor or a list of Tensors, not None \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1096\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39m(layer: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m).\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:822\u001b[0m, in \u001b[0;36mLayer._keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m   \u001b[39mreturn\u001b[39;00m nest\u001b[39m.\u001b[39mmap_structure(keras_tensor\u001b[39m.\u001b[39mKerasTensor, output_signature)\n\u001b[1;32m    821\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 822\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_infer_output_signature(inputs, args, kwargs, input_masks)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:863\u001b[0m, in \u001b[0;36mLayer._infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    857\u001b[0m   \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m    858\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m    859\u001b[0m     \u001b[39m# Build layer if applicable (if the `build` method has been\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[39m# overridden).\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[39m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[39;00m\n\u001b[1;32m    862\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_build(inputs)\n\u001b[0;32m--> 863\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    865\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n\u001b[1;32m    866\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_mask_metadata(inputs, outputs, input_masks,\n\u001b[1;32m    867\u001b[0m                         build_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py:424\u001b[0m, in \u001b[0;36mFunctional.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs, training\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    407\u001b[0m   \u001b[39m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \n\u001b[1;32m    409\u001b[0m \u001b[39m  In this case `call` just reapplies\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[39m      a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 424\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_internal_graph(\n\u001b[1;32m    425\u001b[0m       inputs, training\u001b[39m=\u001b[39;49mtraining, mask\u001b[39m=\u001b[39;49mmask)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py:560\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    557\u001b[0m   \u001b[39mcontinue\u001b[39;00m  \u001b[39m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m args, kwargs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[0;32m--> 560\u001b[0m outputs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39;49mlayer(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    562\u001b[0m \u001b[39m# Update tensor_dict.\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39mfor\u001b[39;00m x_id, y \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(node\u001b[39m.\u001b[39mflat_output_ids, nest\u001b[39m.\u001b[39mflatten(outputs)):\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:998\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_autocast:\n\u001b[1;32m    996\u001b[0m   inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m--> 998\u001b[0m input_spec\u001b[39m.\u001b[39;49massert_input_compatibility(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_spec, inputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m    999\u001b[0m \u001b[39mif\u001b[39;00m eager:\n\u001b[1;32m   1000\u001b[0m   call_fn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/input_spec.py:255\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    253\u001b[0m       value \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39mvalue\n\u001b[1;32m    254\u001b[0m     \u001b[39mif\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m shape_as_list[\u001b[39mint\u001b[39m(axis)] \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m {value, \u001b[39mNone\u001b[39;00m}:\n\u001b[0;32m--> 255\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    256\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(input_index) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m of layer \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m layer_name \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m is\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    257\u001b[0m           \u001b[39m'\u001b[39m\u001b[39m incompatible with the layer: expected axis \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(axis) \u001b[39m+\u001b[39m\n\u001b[1;32m    258\u001b[0m           \u001b[39m'\u001b[39m\u001b[39m of input shape to have value \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(value) \u001b[39m+\u001b[39m\n\u001b[1;32m    259\u001b[0m           \u001b[39m'\u001b[39m\u001b[39m but received input with shape \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m display_shape(x\u001b[39m.\u001b[39mshape))\n\u001b[1;32m    260\u001b[0m \u001b[39m# Check shape.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39mshape \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m shape\u001b[39m.\u001b[39mrank \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer fc1 is incompatible with the layer: expected axis -1 of input shape to have value 25088 but received input with shape (None, 32768)"
     ]
    }
   ],
   "source": [
    "\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='mse', optimizer=common_optimizer, \n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "generator = build_generator()\n",
    "\n",
    "input_high_resolution = Input(shape=high_resolution_shape)\n",
    "input_low_resolution = Input(shape=low_resolution_shape)\n",
    "\n",
    "generated_high_resolution_images = generator(input_low_resolution)\n",
    "\n",
    "features = vgg(generated_high_resolution_images)\n",
    "\n",
    "discriminator.trainable = False\n",
    "\n",
    "probs = discriminator(generated_high_resolution_images)\n",
    "\n",
    "adversarial_model = Model([input_low_resolution, input_high_resolution], [probs, features])\n",
    "adversarial_model.compile(loss=['binary_crossentropy', 'mse'], \n",
    "            loss_weights=[1e-3, 1], optimizer=common_optimizer)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/\".format(time.time()))\n",
    "tensorboard.set_model(generator)\n",
    "tensorboard.set_model(discriminator)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch:{}\".format(epoch))\n",
    "\n",
    "high_resolution_images, low_resolution_images = sample_images(data_dir=data_dir,   \n",
    "    batch_size=batch_size,low_resolution_shape=low_resolution_shape,                                                                \n",
    "    high_resolution_shape=high_resolution_shape)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
