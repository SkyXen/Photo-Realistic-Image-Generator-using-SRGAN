{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 16:45:52.103773: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 16:45:55.977915: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-04-08 16:45:55.978909: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-04-08 16:45:55.997516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-08 16:45:55.997751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1650 Ti computeCapability: 7.5\n",
      "coreClock: 1.485GHz coreCount: 16 deviceMemorySize: 3.81GiB deviceMemoryBandwidth: 178.84GiB/s\n",
      "2023-04-08 16:45:55.997782: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-04-08 16:45:56.017346: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-04-08 16:45:56.017454: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-04-08 16:45:56.029126: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-04-08 16:45:56.032385: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-04-08 16:45:56.061662: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-04-08 16:45:56.065499: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-04-08 16:45:56.106160: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-04-08 16:45:56.106412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-08 16:45:56.106656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-08 16:45:56.106775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PREPROCESSING\n",
    "\n",
    "train_dir = \"data\"\n",
    "\n",
    "for img in os.listdir(train_dir + \"/original\"):\n",
    "    img_arr = cv2.imread(train_dir + \"/original/\" + img)\n",
    "    img_arr = cv2.resize(img_arr,(128,128))\n",
    "    lr_img_arr = cv2.resize(img_arr,(32,32))\n",
    "    cv2.imwrite(train_dir + \"/hr/\" + img, img_arr)\n",
    "    cv2.imwrite(train_dir + \"/lr/\" + img, lr_img_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x):\n",
    "    \"\"\"\n",
    "    Residual block\n",
    "    \"\"\"\n",
    "    filters = [64, 64]\n",
    "    kernel_size = 3\n",
    "    strides = 1\n",
    "    padding = \"same\"\n",
    "    momentum = 0.8\n",
    "    activation = \"relu\"\n",
    "\n",
    "    res = Conv2D(filters=filters[0], kernel_size=kernel_size, \n",
    "                 strides=strides, padding=padding)(x)\n",
    "    res = Activation(activation=activation)(res)\n",
    "    res = BatchNormalization(momentum=momentum)(res)\n",
    "\n",
    "    res = Conv2D(filters=filters[1], kernel_size=kernel_size, \n",
    "                 strides=strides, padding=padding)(res)\n",
    "    res = BatchNormalization(momentum=momentum)(res)\n",
    "\n",
    "    # Add res and x\n",
    "    res = Add()([res, x])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator Network\n",
    "def build_generator(gen_input):\n",
    "    \"\"\"\n",
    "    Create a generator network using the hyperparameter values defined below\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    residual_blocks = 16\n",
    "    momentum = 0.8\n",
    "    # Input Layer of the generator network\n",
    "    input_layer = gen_input\n",
    "\n",
    "    # Add the pre-residual block\n",
    "    gen1 = Conv2D(filters=64, kernel_size=9, strides=1, padding='same',  \n",
    "                  activation='relu')(input_layer)\n",
    "\n",
    "    # Add 16 residual blocks\n",
    "    res = residual_block(gen1)\n",
    "    for i in range(residual_blocks - 1):\n",
    "        res = residual_block(res)\n",
    "\n",
    "    # Add the post-residual block\n",
    "    gen2 = Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(res)\n",
    "    gen2 = BatchNormalization(momentum=momentum)(gen2)\n",
    "\n",
    "    # Take the sum of the output from the pre-residual block(gen1) and the post-residual block(gen2)\n",
    "    gen3 = Add()([gen2, gen1])\n",
    "\n",
    "    # Add an upsampling block\n",
    "    gen4 = UpSampling2D(size=2)(gen3)\n",
    "    gen4 = Conv2D(filters=256, kernel_size=3, strides=1, padding='same')(gen4)\n",
    "    gen4 = Activation('relu')(gen4)\n",
    "\n",
    "    # Add another upsampling block\n",
    "    gen5 = UpSampling2D(size=2)(gen4)\n",
    "    gen5 = Conv2D(filters=256, kernel_size=3, strides=1, \n",
    "                  padding='same')(gen5)\n",
    "    gen5 = Activation('relu')(gen5)\n",
    "\n",
    "    # Output convolution layer\n",
    "    gen6 = Conv2D(filters=3, kernel_size=9, strides=1, padding='same')(gen5)\n",
    "    output = Activation('tanh')(gen6)\n",
    "\n",
    "    # Keras model\n",
    "    model = Model(inputs=[input_layer], outputs=[output], \n",
    "                  name='generator')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(dis_input):\n",
    "    \"\"\"\n",
    "    Create a discriminator network using the hyperparameter values defined below\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    leakyrelu_alpha = 0.2\n",
    "    momentum = 0.8\n",
    "\n",
    "    input_layer = dis_input\n",
    "\n",
    "    # Add the first convolution block\n",
    "    dis1 = Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(input_layer)\n",
    "    dis1 = LeakyReLU(alpha=leakyrelu_alpha)(dis1)\n",
    "\n",
    "    # Add the 2nd convolution block\n",
    "    dis2 = Conv2D(filters=64, kernel_size=3, strides=2, padding='same')(dis1)\n",
    "    dis2 = LeakyReLU(alpha=leakyrelu_alpha)(dis2)\n",
    "    dis2 = BatchNormalization(momentum=momentum)(dis2)\n",
    "\n",
    "    # Add the third convolution block\n",
    "    dis3 = Conv2D(filters=128, kernel_size=3, strides=1, padding='same')(dis2)\n",
    "    dis3 = LeakyReLU(alpha=leakyrelu_alpha)(dis3)\n",
    "    dis3 = BatchNormalization(momentum=momentum)(dis3)\n",
    "\n",
    "    # Add the fourth convolution block\n",
    "    dis4 = Conv2D(filters=128, kernel_size=3, strides=2, padding='same')(dis3)\n",
    "    dis4 = LeakyReLU(alpha=leakyrelu_alpha)(dis4)\n",
    "    dis4 = BatchNormalization(momentum=0.8)(dis4)\n",
    "\n",
    "    # Add the fifth convolution block\n",
    "    dis5 = Conv2D(256, kernel_size=3, strides=1, padding='same')(dis4)\n",
    "    dis5 = LeakyReLU(alpha=leakyrelu_alpha)(dis5)\n",
    "    dis5 = BatchNormalization(momentum=momentum)(dis5)\n",
    "\n",
    "    # Add the sixth convolution block\n",
    "    dis6 = Conv2D(filters=256, kernel_size=3, strides=2, padding='same')(dis5)\n",
    "    dis6 = LeakyReLU(alpha=leakyrelu_alpha)(dis6)\n",
    "    dis6 = BatchNormalization(momentum=momentum)(dis6)\n",
    "\n",
    "    # Add the seventh convolution block\n",
    "    dis7 = Conv2D(filters=512, kernel_size=3, strides=1, padding='same')(dis6)\n",
    "    dis7 = LeakyReLU(alpha=leakyrelu_alpha)(dis7)\n",
    "    dis7 = BatchNormalization(momentum=momentum)(dis7)\n",
    "\n",
    "    # Add the eight convolution block\n",
    "    dis8 = Conv2D(filters=512, kernel_size=3, strides=2, padding='same')(dis7)\n",
    "    dis8 = LeakyReLU(alpha=leakyrelu_alpha)(dis8)\n",
    "    dis8 = BatchNormalization(momentum=momentum)(dis8)\n",
    "\n",
    "    # Add a dense layer\n",
    "    dis9 = Dense(units=1024)(dis8)\n",
    "    dis9 = LeakyReLU(alpha=0.2)(dis9)\n",
    "\n",
    "    # Last dense layer - for classification\n",
    "    output = Dense(units=1, activation='sigmoid')(dis9)\n",
    "\n",
    "    model = Model(inputs=[input_layer], outputs=[output], name='discriminator')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_adversarial_model(generator, discriminator, vgg):\n",
    "\n",
    "    input_low_resolution = Input(shape=(64, 64, 3))\n",
    "\n",
    "    fake_hr_images = generator(input_low_resolution)\n",
    "    fake_features = vgg(fake_hr_images)\n",
    "\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    output = discriminator(fake_hr_images)\n",
    "\n",
    "    model = Model(inputs=[input_low_resolution],\n",
    "                  outputs=[output, fake_features])\n",
    "\n",
    "    for layer in model.layers:\n",
    "        print(layer.name, layer.trainable)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sample_images(data_dir, batch_size, high_resolution_shape, low_resolution_shape):\n",
    "#     # Make a list of all images inside the data directory\n",
    "#     all_images = glob.glob(data_dir)\n",
    "\n",
    "#     # Choose a random batch of images\n",
    "#     images_batch = np.random.choice(all_images, size=batch_size)\n",
    "\n",
    "#     low_resolution_images = []\n",
    "#     high_resolution_images = []\n",
    "\n",
    "#     for img in images_batch:\n",
    "#         # Get an ndarray of the current image\n",
    "#         img1 = load_img(img, mode='RGB')\n",
    "#         img1 = img1.astype(np.float32)\n",
    "\n",
    "#         # Resize the image\n",
    "#         img1_high_resolution = smart_resize(img1, high_resolution_shape)\n",
    "#         img1_low_resolution = smart_resize(img1, low_resolution_shape)\n",
    "\n",
    "#         # Do a random flip\n",
    "#         if np.random.random() < 0.5:\n",
    "#             img1_high_resolution = np.fliplr(img1_high_resolution)\n",
    "#             img1_low_resolution = np.fliplr(img1_low_resolution)\n",
    "\n",
    "#         high_resolution_images.append(img1_high_resolution)\n",
    "#         low_resolution_images.append(img1_low_resolution)\n",
    "\n",
    "#     return np.array(high_resolution_images), np.array(low_resolution_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vgg(high_resolution_shape):\n",
    "    vgg = VGG19(weights = 'imagenet', include_top=False, input_shape=high_resolution_shape)\n",
    "\n",
    "    return Model(inputs = vgg.inputs, outputs = vgg.layers[10].output)\n",
    "\n",
    "def create_combination(generator,discriminator,vgg,input_low_resolution,input_high_resolution):\n",
    "    generated_high_resolution_images = generator(input_low_resolution)\n",
    "\n",
    "    features = vgg(generated_high_resolution_images)\n",
    "\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    probs = discriminator(generated_high_resolution_images)\n",
    "\n",
    "    adversarial_model = Model(inputs=[input_low_resolution, input_high_resolution], outputs=[probs, features])\n",
    "    \n",
    "    return adversarial_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Laoding images\n",
    "n = 5000\n",
    "lr_list = os.listdir(\"data/lr\")[:n]\n",
    "\n",
    "lr_images = []\n",
    "for img in lr_list:\n",
    "    img_lr = cv2.imread(\"data/lr/\" + img)\n",
    "    img_lr = cv2.cvtColor(img_lr,cv2.COLOR_BGR2RGB)\n",
    "    lr_images.append(img_lr)\n",
    "\n",
    "hr_list = os.listdir(\"data/hr\")[:n]\n",
    "hr_images = []\n",
    "for img in hr_list:\n",
    "    img_hr = cv2.imread(\"data/hr/\" + img)\n",
    "    img_hr = cv2.cvtColor(img_hr,cv2.COLOR_BGR2RGB)\n",
    "    hr_images.append(img_hr)\n",
    "\n",
    "lr_images = np.array(lr_images)\n",
    "hr_images = np.array(hr_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viewing some images\n",
    "import random\n",
    "image_number = random.randint(0,len(lr_images)-1)\n",
    "plt.figure(figsize = (12,6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(np.reshape(lr_images[image_number],(32,32,3)))\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.reshape(hr_images[image_number],(128,128,3)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale values\n",
    "\n",
    "lr_images = lr_images/255\n",
    "hr_images = hr_images/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "lr_train, lr_test, hr_train, hr_test = train_test_split(lr_images,hr_images,test_size=0.3,random_state=100)\n",
    "\n",
    "low_resolution_shape = (lr_train.shape[1], lr_train.shape[2], lr_train.shape[3])\n",
    "high_resolution_shape = (hr_train.shape[1], hr_train.shape[2], hr_train.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Shape of low-resolution and high-resolution images\n",
    "input_low_resolution = Input(shape=low_resolution_shape)\n",
    "input_high_resolution = Input(shape=high_resolution_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_generator(input_low_resolution)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common optimizer for all networks\n",
    "common_optimizer = Adam(0.0002, 0.5)\n",
    "discriminator = build_discriminator(input_high_resolution)\n",
    "discriminator.compile(loss='mse', optimizer=common_optimizer, \n",
    "                      metrics=['accuracy'])\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = build_vgg((128,128,3))\n",
    "print(vgg.summary())\n",
    "vgg.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_model = create_combination(generator,discriminator,vgg,input_low_resolution,input_high_resolution)\n",
    "gan_model.compile(loss=[\"binary_crossentropy\",\"mse\"], loss_weights=[1e-3, 1], \n",
    "                  optimizer=common_optimizer)\n",
    "gan_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_model = build_adversarial_model(generator,discriminator,vgg)\n",
    "adv_model.compile(loss=[\"binary_crossentropy\",\"mse\"], loss_weights=[1e-3, 1], \n",
    "                  optimizer=common_optimizer)\n",
    "adv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "epochs = 15\n",
    "batch_size = 1\n",
    "\n",
    "train_lr_batches = []\n",
    "train_hr_batches = []\n",
    "\n",
    "for it in range(int(hr_train.shape[0]/batch_size)):\n",
    "    start_idx = it*batch_size\n",
    "    end_idx = start_idx + batch_size\n",
    "    train_hr_batches.append(hr_train[start_idx:end_idx])\n",
    "    train_lr_batches.append(lr_train[start_idx:end_idx])\n",
    "\n",
    "for e in range(epochs):\n",
    "    fake_label = np.zeros((batch_size,1)) #Assign a label of 0 to all fake generated images\n",
    "    real_label = np.ones((batch_size,1)) #Assign a label of 1 to all real images\n",
    "\n",
    "    #List for losses of generator and discrimanator\n",
    "    gen_losses = []\n",
    "    dis_losses = []\n",
    "\n",
    "    for b in tqdm(range(len(train_hr_batches))):\n",
    "        lr_imgs = train_lr_batches[b]\n",
    "        hr_imgs = train_hr_batches[b]\n",
    "\n",
    "        fake_imgs = generator.predict_on_batch(lr_imgs)\n",
    "\n",
    "        discriminator.trainable = True\n",
    "\n",
    "        d_loss_gen = discriminator.train_on_batch(fake_imgs,fake_label)\n",
    "        d_loss_real = discriminator.train_on_batch(hr_imgs,real_label)\n",
    "\n",
    "        discriminator.trainable = False\n",
    "\n",
    "        d_loss = 0.5 * np.add(d_loss_gen, d_loss_real)\n",
    "\n",
    "        image_features = vgg.predict(hr_imgs)\n",
    "        g_loss, _, _ = gan_model.train_on_batch([lr_imgs, hr_imgs], [real_label, image_features])\n",
    "\n",
    "        \n",
    "        #Save losses to a list so we can average and report. \n",
    "        dis_losses.append(d_loss)\n",
    "        gen_losses.append(g_loss)\n",
    "        \n",
    "    #Convert the list of losses to an array to make it easy to average    \n",
    "    gen_losses = np.array(gen_losses)\n",
    "    dis_losses = np.array(dis_losses)\n",
    "    \n",
    "    #Calculate the average losses for generator and discriminator\n",
    "    g_loss = np.sum(gen_losses, axis=0) / len(gen_losses)\n",
    "    d_loss = np.sum(dis_losses, axis=0) / len(dis_losses)\n",
    "    \n",
    "    #Report the progress during training. \n",
    "    print(\"epoch:\", e+1 , \"g_loss: \", g_loss, \"d_loss:\", d_loss)\n",
    "\n",
    "    if (e+1) % 10 == 0: #Change the frequency for model saving, if needed\n",
    "        #Save the generator after every n epochs (Usually 10 epochs)\n",
    "        generator.save(\"gen_e_\"+ str(e+1) +\".h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################\n",
    "#Test - perform super resolution using saved generator model\n",
    "from tensorflow.keras.models import load_model\n",
    "from numpy.random import randint\n",
    "\n",
    "generator = load_model('gen_e_10.h5', compile=False)\n",
    "\n",
    "\n",
    "[X1, X2] = [lr_test, hr_test]\n",
    "# select random example\n",
    "ix = randint(0, len(X1), 1)\n",
    "src_image, tar_image = X1[ix], X2[ix]\n",
    "\n",
    "# generate image from source\n",
    "gen_image = generator.predict(src_image)\n",
    "\n",
    "\n",
    "# plot all three images\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(231)\n",
    "plt.title('LR Image')\n",
    "plt.imshow(src_image[0,:,:,:])\n",
    "plt.subplot(232)\n",
    "plt.title('Superresolution')\n",
    "plt.imshow(gen_image[0,:,:,:])\n",
    "plt.subplot(233)\n",
    "plt.title('Orig. HR image')\n",
    "plt.imshow(tar_image[0,:,:,:])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "################################################\n",
    "sreeni_lr = cv2.imread(\"data/sreeni_32.jpg\")\n",
    "sreeni_hr = cv2.imread(\"data/sreeni_256.jpg\")\n",
    "\n",
    "#Change images from BGR to RGB for plotting. \n",
    "#Remember that we used cv2 to load images which loads as BGR.\n",
    "sreeni_lr = cv2.cvtColor(sreeni_lr, cv2.COLOR_BGR2RGB)\n",
    "sreeni_hr = cv2.cvtColor(sreeni_hr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "sreeni_lr = sreeni_lr / 255.\n",
    "sreeni_hr = sreeni_hr / 255.\n",
    "\n",
    "sreeni_lr = np.expand_dims(sreeni_lr, axis=0)\n",
    "sreeni_hr = np.expand_dims(sreeni_hr, axis=0)\n",
    "\n",
    "generated_sreeni_hr = generator.predict(sreeni_lr)\n",
    "\n",
    "# plot all three images\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(231)\n",
    "plt.title('LR Image')\n",
    "plt.imshow(sreeni_lr[0,:,:,:])\n",
    "plt.subplot(232)\n",
    "plt.title('Superresolution')\n",
    "plt.imshow(generated_sreeni_hr[0,:,:,:])\n",
    "plt.subplot(233)\n",
    "plt.title('Orig. HR image')\n",
    "plt.imshow(sreeni_hr[0,:,:,:])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
